# AIME 2025 benchmark configuration
# Uses 2x A100 tensor parallel for longer context
env_id: aime2025

infra:
  gpu: "A100-80GB:2"

vllm:
  max_model_len: 40960
  tensor_parallel_size: 2
  data_parallel_size: 1

sampling:
  temperature: 0.7
  max_tokens: 32768

eval:
  rollouts: 32
  num_examples: 30

chat_template: math
